{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87741af0",
   "metadata": {},
   "source": [
    "# BioData Catalyst Data Release QA\n",
    "Validation tests in this notebook:\n",
    "1. [**Patient counts of new studies**](https://basicnotebookinstance-rl0ytn08jb87.notebook.us-east-1.sagemaker.aws/notebooks/biodatacatalyst-pic-sure/access-dashboard-metadata/biodatacatalyst_data_release_QA.ipynb#Validation:-New-study-patient-counts): Patient counts of the new studies from the integration environment are compared to the patient counts in Patient_Count_Per_Consents.csv\n",
    "2. [**Data dictionary comparison**](https://basicnotebookinstance-rl0ytn08jb87.notebook.us-east-1.sagemaker.aws/notebooks/biodatacatalyst-pic-sure/access-dashboard-metadata/biodatacatalyst_data_release_QA.ipynb#Validation:-Data-dictionary-comparison): Integration and production data dictionaries are compared to ensure complete match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc9c04",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "- Developer access to the integration enviroment (token)\n",
    "- Consent value(s) of the new study (or studies) to validate (phs number)\n",
    "- Knowledge on whether a harmonized study was added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc642ed",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ee04b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from shutil import copyfile\n",
    "import PicSureClient\n",
    "import PicSureBdcAdapter\n",
    "\n",
    "from utils import get_full_consent_vals, compare_datadict_indices, compare_datadicts, get_topmed_and_harmonized_consents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ec7db",
   "metadata": {},
   "source": [
    "### Connect to PIC-SURE\n",
    "Be sure to use the **developer token** from the **integration environment**. It is necessary to have access to all studies to validate the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c18132",
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_PICSURE_network_URL = \"https://biodatacatalyst.integration.hms.harvard.edu/picsure\"\n",
    "#int_resource_id = \"02e23f52-f354-4e8b-992c-d37c8b9ba140\"\n",
    "int_resource_id = \"70c837be-5ffc-11eb-ae93-0242ac130002\" # Open access\n",
    "integration_token_file = \"token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f076ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(integration_token_file, \"r\") as f:\n",
    "    my_int_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_client = PicSureClient.Client()\n",
    "int_connection = int_client.connect(integration_PICSURE_network_URL, my_int_token, True)\n",
    "int_adapter = PicSureBdcAdapter.Adapter(int_connection)\n",
    "int_resource = int_adapter.useResource(int_resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6f1fd",
   "metadata": {},
   "source": [
    "## Validation: New study patient counts\n",
    "The purpose of this section is to validate the patient counts for newly ingested studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1f91c",
   "metadata": {},
   "source": [
    "### Specify the new study (or studies) to be tested\n",
    "To validate the new studies ingested, specify the phs numbers in the cell below without the consent group. \n",
    "For example, if the study of interest is the AMISH study, list `phs000956` below (*not* `phs000956.c1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_validate = ['list', 'phs_numbers', 'here']\n",
    "to_validate = ['phs000287', #CHS,\n",
    "               'phs000200', #WHI\n",
    "               'phs000280' #ARIC\n",
    "              ]\n",
    "\n",
    "to_validate_topmed, to_validate_harmonized = get_topmed_and_harmonized_consents(to_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feec32d",
   "metadata": {},
   "source": [
    "### Get patient count file from S3 bucket\n",
    "This notebook uses `Patient_Count_Per_Consents.csv` from the S3 bucket as the reference file. First we need to copy this file over to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21addfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '/home/ec2-user/SageMaker/studies/ALL-avillach-73-bdcatalyst-etl/general/completed/Patient_Count_Per_Consents.csv'\n",
    "dst = '/home/ec2-user/SageMaker/biodatacatalyst-pic-sure/access-dashboard-metadata/Patient_Count_Per_Consents.csv'\n",
    "copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86729100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load S3 file as a dataframe in the Jupyter Notebook\n",
    "patient_ref_file = pd.read_csv('Patient_Count_Per_Consents.csv', header=None, names=['consent', 'patient_count'])\n",
    "patient_ref_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912de560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the consent groups based on the user-identified phs values\n",
    "full_phs = get_full_consent_vals(to_validate, patient_ref_file)\n",
    "full_phs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d351e8d1",
   "metadata": {},
   "source": [
    "### Get patient count for the specified consent groups\n",
    "Now the consent groups will be used to find the patient counts currently in the integration environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3349de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new query and initialize output dictionary\n",
    "patient_count_query = int_resource.query()\n",
    "output = {}\n",
    "\n",
    "# Get patient counts for each consent group\n",
    "for consentGroup in full_phs:\n",
    "    print(consentGroup)\n",
    "    patient_count_query.filter().delete(\"\\\\_consents\\\\\") # Delete all consents\n",
    "    patient_count_query.filter().add(\"\\\\_consents\\\\\", consentGroup) # Add back consent group of interest\n",
    "    patient_count = patient_count_query.getCount() # Get patient count\n",
    "    output[consentGroup] = patient_count # Add to output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6ee53",
   "metadata": {},
   "source": [
    "### Compare the values to the reference file\n",
    "Finally we will compare the values from the reference file to the counts in the integration environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for consent_val in output.keys():\n",
    "    ref_count = int(patient_ref_file[patient_ref_file['consent'] == consent_val]['patient_count']) # Count from reference file\n",
    "    integration_count = output[consent_val] # Count from integration environment\n",
    "    # Display result message\n",
    "    if ref_count == integration_count:\n",
    "        print(consent_val, \"passes validation\")\n",
    "    else:\n",
    "        print('***DID NOT PASS VALIDATION:', consent_val)\n",
    "        print('Expected count from Patient_Count_Per_Consents.csv:\\t', ref_count)\n",
    "        print('Count retrieved from integration environment:\\t', integration_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15694184",
   "metadata": {},
   "source": [
    "## Validation: Data dictionary comparison\n",
    "The purpose of this section is to compare the data dictionaries of the production and integration environments. These data dictionaries should be identical besides the studies that are being loaded and/or updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19f51f",
   "metadata": {},
   "source": [
    "### Establish connection to production environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bab180",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_PICSURE_network_URL = \"https://picsure.biodatacatalyst.nhlbi.nih.gov/picsure\"\n",
    "#prod_resource_id = \"02e23f52-f354-4e8b-992c-d37c8b9ba140\"\n",
    "prod_resource_id = \"70c837be-5ffc-11eb-ae93-0242ac130002\" # Open access\n",
    "production_token_file = \"prod_token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55038402",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(production_token_file, \"r\") as f:\n",
    "    my_prod_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_client = PicSureClient.Client()\n",
    "prod_connection = prod_client.connect(production_PICSURE_network_URL, my_prod_token, True)\n",
    "prod_adapter = PicSureBdcAdapter.Adapter(prod_connection)\n",
    "prod_resource = prod_adapter.useResource(prod_resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d6a78",
   "metadata": {},
   "source": [
    "### Load data dictionaries\n",
    "Next we will load the data dictionaries from the integration and production environments as dataframes. These will be used to compare the environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b06d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_dictionary = int_resource.dictionary()\n",
    "prod_dictionary = prod_resource.dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "integ = int_dictionary.find().DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = prod_dictionary.find().DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889370fd",
   "metadata": {},
   "source": [
    "### Compare dictionaries\n",
    "The following comparisons will be made between the dictionaries:\n",
    "1. Find concept paths that exist in integration, but not production\n",
    "2. Find concept paths that exist in production, but not integration\n",
    "3. Identify differences in the dataframe between integration and production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c3ad47",
   "metadata": {},
   "source": [
    "The first comparisons use the concept paths, which we will extract and compare now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89afc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_comparison = compare_datadict_indices(integ, prod, 1, to_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d575a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_comparison = compare_datadict_indices(prod, integ, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d8e16",
   "metadata": {},
   "source": [
    "The third comparison compares the data in the data dictionary. The following function iterates through each row of the data dictionary and compares the integration and production results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01517723",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonized = get_full_consent_vals(to_validate_harmonized, patient_ref_file)\n",
    "topmed = get_full_consent_vals(to_validate_topmed, patient_ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check = compare_datadicts(integ, prod, to_validate, full_phs, harmonized, topmed, patient_ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57979641",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4def5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For next QA process:\n",
    "# Run counts for each value under _studies_consents - compare between Integration and Production\n",
    "\n",
    "# Do patient counts for the following, if there is a change, be able to explain:\n",
    "# All _studies have values for _studies_consents and _consents (_parent_consents, _topmed_consents)\n",
    "# All top-level paths for studies have values in _consents and _studies_consents and _studies (_parent_consents, _topmed_consents)\n",
    "\n",
    "\n",
    "\n",
    "# Create a table for each environment\n",
    "# Compare the tables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
